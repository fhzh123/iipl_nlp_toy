{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "captioning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4rS6JTxwmma"
      },
      "source": [
        "!pip install scipy==1.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn9npwxTwoxi"
      },
      "source": [
        "from google.colab import files\r\n",
        "\r\n",
        "src = list(files.upload().values())[0]\r\n",
        "open('caption.py', 'wb').write(src)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F9mJppgwrxm"
      },
      "source": [
        "src = list(files.upload().values())[0]\r\n",
        "open('models.py', 'wb').write(src)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAJLZ3HbwvF0"
      },
      "source": [
        "import caption\r\n",
        "import torch\r\n",
        "import json\r\n",
        "import os\r\n",
        "from collections import OrderedDict\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "checkpoint = torch.load('/content/drive/MyDrive/data/BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar', map_location=str(device))\r\n",
        "decoder = checkpoint['decoder']\r\n",
        "decoder = decoder.to(device)\r\n",
        "decoder.eval()\r\n",
        "encoder = checkpoint['encoder']\r\n",
        "encoder = encoder.to(device)\r\n",
        "encoder.eval()\r\n",
        "\r\n",
        "# Load word map (word2ix)\r\n",
        "with open('/content/drive/MyDrive/data/WORDMAP_coco_5_cap_per_img_5_min_word_freq.json', 'r') as j:\r\n",
        "    word_map = json.load(j)\r\n",
        "rev_word_map = {v: k for k, v in word_map.items()}  # ix2word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HvMUGylwzW-"
      },
      "source": [
        "path_dir = '/content/drive/MyDrive/data/aliceintotherabbithole'\r\n",
        "file_list = os.listdir(path_dir)\r\n",
        "\r\n",
        "alice_data = []\r\n",
        "for img_name in file_list:\r\n",
        "  try:\r\n",
        "    Image.open(path_dir+'/'+img_name) \r\n",
        "  except:\r\n",
        "    continue\r\n",
        "\r\n",
        "  # Encode, decode with attention and beam search\r\n",
        "  seq, alphas = caption.caption_image_beam_search(encoder, decoder, path_dir+'/'+img_name, word_map, 3)\r\n",
        "  alphas = torch.FloatTensor(alphas)\r\n",
        "\r\n",
        "  # Visualize caption and attention of best sequence\r\n",
        "  words = caption.visualize_att(path_dir+'/'+img_name, seq, alphas, rev_word_map, smooth=True)\r\n",
        "  data = {'file_name': img_name, 'caption': words}\r\n",
        "  alice_data.append(data)\r\n",
        "  print(len(alice_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tdhBvmiw16l"
      },
      "source": [
        "json_data = OrderedDict()\r\n",
        "json_data['alice'] = alice_data\r\n",
        "with open('alice.json', 'w', encoding=\"utf-8\") as make_file:\r\n",
        "    json.dump(json_data, make_file, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}